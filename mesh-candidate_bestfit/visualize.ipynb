{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a332dc-77d5-4350-a05a-1e33d14ad8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from einops import rearrange\n",
    "from torch import BoolTensor, FloatTensor, LongTensor\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc85f6f4-27d4-4c98-a2a6-ff9cd5a390c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_layout_to_image(\n",
    "    boxes: FloatTensor,\n",
    "    labels: LongTensor,\n",
    "    colors: List[Tuple[int]],\n",
    "    canvas_size: Optional[Tuple[int]] = None,\n",
    "    resources: Optional[Dict] = None,\n",
    "    names: Optional[Tuple[str]] = None,\n",
    "    index: bool = False,\n",
    "    **kwargs,\n",
    "):\n",
    "    H, W = canvas_size\n",
    "    if names or index:\n",
    "        font = ImageFont.load_default()\n",
    "    if resources:\n",
    "        img = resources[\"img_bg\"].resize((W, H))\n",
    "    else:\n",
    "        img = Image.new(\"RGB\", (int(W), int(H)), color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img, \"RGBA\")\n",
    "    \n",
    "    for i in range(boxes.shape[0]):\n",
    "        bbox, label = boxes[i], labels[i]\n",
    "        if isinstance(label, LongTensor):\n",
    "            label = label.item()\n",
    "\n",
    "        c_fill = colors[label] + (100,)\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1, x2 = x1 * (W - 1), x2 * (W - 1)\n",
    "        y1, y2 = y1 * (H - 1), y2 * (H - 1)\n",
    "\n",
    "        if resources:\n",
    "            patch = resources[\"cropped_patches\"][i]\n",
    "            # round coordinates for exact size match for rendering images\n",
    "            x1, x2 = int(x1), int(x2)\n",
    "            y1, y2 = int(y1), int(y2)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            patch = patch.resize((w, h))\n",
    "            img.paste(patch, (x1, y1))\n",
    "        else:\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=colors[label], fill=c_fill)\n",
    "            if names:\n",
    "                draw.text((x1, y1), names[label], \"black\", font=font)\n",
    "            elif index:\n",
    "                draw.text((x1, y1), str(int(i % (len(labels)/2))), \"black\", font=font)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c6186",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcff0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = './M6Doc_annotation_file.json'  # dataset original annotation file\n",
    "category_list = json.load(open(json_path))['categories']\n",
    "name_list = [category_list[idx]['name'] for idx in range(len(category_list))] # category names\n",
    "name_num = len(name_list)  # category number\n",
    "print(name_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064f998",
   "metadata": {},
   "source": [
    "### Set colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = tuple([tuple(map(int,tuple((torch.rand(1,3).squeeze(0)*255).tolist()))) for _ in range(name_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b97448-2386-4818-8f61-e28ec3928b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(\n",
    "    batch_boxes: FloatTensor,\n",
    "    batch_labels: LongTensor,\n",
    "    batch_mask: BoolTensor,\n",
    "    out_path: Optional[Union[pathlib.PosixPath, str]] = None,\n",
    "    canvas_size: Optional[Tuple[int]] = (1600, 1600),\n",
    "    nrow: Optional[int] = None,\n",
    "    batch_resources: Optional[Dict] = None,\n",
    "    use_grid: bool = True,\n",
    "    draw_label: bool = False,\n",
    "    draw_index: bool = False,\n",
    "    dataset: str = 'publaynet'\n",
    "):\n",
    "    # batch_boxes: [B, N, 4]\n",
    "    # batch_labels: [B, N]\n",
    "    # batch_mask: [B, N]\n",
    "\n",
    "    if isinstance(out_path, pathlib.PosixPath):\n",
    "        out_path = str(out_path)\n",
    "\n",
    "    colors = COLORS\n",
    "\n",
    "    if not draw_label:\n",
    "        names = None\n",
    "    else:\n",
    "        names = name_list\n",
    "\n",
    "    imgs = []\n",
    "    B = batch_boxes.size(0)\n",
    "    to_tensor = T.ToTensor()\n",
    "    for i in range(B):\n",
    "        mask_i = batch_mask[i]\n",
    "        boxes = batch_boxes[i][mask_i]\n",
    "        labels = batch_labels[i][mask_i]\n",
    "        if batch_resources:\n",
    "            resources = {k: v[i] for (k, v) in batch_resources.items()}\n",
    "            img = convert_layout_to_image(boxes, labels, colors, canvas_size, resources, names=names, index=draw_index)\n",
    "        else:\n",
    "            img = convert_layout_to_image(boxes, labels, colors, canvas_size, names=names, index=draw_index)\n",
    "        imgs.append(to_tensor(img))\n",
    "    image = torch.stack(imgs)\n",
    "\n",
    "    if nrow is None:\n",
    "        nrow = int(np.ceil(np.sqrt(B)))\n",
    "\n",
    "    if out_path:\n",
    "        vutils.save_image(image, out_path, normalize=False, nrow=nrow)\n",
    "    else:\n",
    "        if use_grid:\n",
    "            return torch_to_numpy_image(\n",
    "                vutils.make_grid(image, normalize=False, nrow=nrow)\n",
    "            )\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "            \n",
    "def torch_to_numpy_image(input_th: FloatTensor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args\n",
    "        input_th: (C, H, W), in [0.0, 1/0], torch image\n",
    "    Returns\n",
    "        output_npy: (H, W, C), in {0, 1, ..., 255}, numpy image\n",
    "    \"\"\"\n",
    "    x = (input_th * 255.0).clamp(0, 255)\n",
    "    x = rearrange(x, \"c h w -> h w c\")\n",
    "    output_npy = x.numpy().astype(np.uint8)\n",
    "    return output_npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd95cd-228f-4bcf-a489-915be5d76431",
   "metadata": {},
   "source": [
    "### Visualize layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0932ba9-fd74-4ca5-9df8-7d4dffb5e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_all = json.load(open(\"./generated_layouts/combined_layouts.json\"))  # your generated layouts path\n",
    "\n",
    "MAX_BBOXES_NUM = 50  # set the maximum number of elements in a single layout\n",
    "batch_size = 1       # display how many layouts at a time\n",
    "scale_factor = 160\n",
    "\n",
    "base_index = [idx for idx in range(0,batch_size)]\n",
    "index_all = [batch_size*(scale_factor-1)+x for x in base_index]   # layouts idx for those are displayed\n",
    "\n",
    "batch_bbox, batch_category, batch_mask = [], [], []\n",
    "for batch in range(batch_size):\n",
    "    layout = layout_all[index_all[batch]]\n",
    "    bbox, category = layout[\"boxes\"], layout[\"categories\"]\n",
    "    bbox = torch.Tensor(bbox)\n",
    "    real_bbox = torch.zeros(MAX_BBOXES_NUM,4)\n",
    "    real_bbox[:bbox.shape[0]] = bbox\n",
    "    real_category = torch.ones(MAX_BBOXES_NUM)*5\n",
    "    category = torch.Tensor(category)\n",
    "    real_category[:category.shape[0]] = category\n",
    "    real_mask = torch.ones(MAX_BBOXES_NUM).bool()\n",
    "    real_mask[bbox.shape[0]:] = False\n",
    "    batch_bbox.append(real_bbox.unsqueeze(0))\n",
    "    batch_category.append(real_category.unsqueeze(0))\n",
    "    batch_mask.append(real_mask.unsqueeze(0))\n",
    "batch_bbox = torch.cat(batch_bbox, dim=0)\n",
    "batch_category = torch.cat(batch_category, dim=0).long()\n",
    "batch_mask = torch.cat(batch_mask, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "626bcea8-3495-431a-9d89-2ebf8a79c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAW_LABEL = False\n",
    "batch_image = save_image(batch_bbox, batch_category, batch_mask, canvas_size = (1584,1224), draw_label=DRAW_LABEL)\n",
    "plt.figure(figsize=[12, 12])\n",
    "plt.imshow(batch_image)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
